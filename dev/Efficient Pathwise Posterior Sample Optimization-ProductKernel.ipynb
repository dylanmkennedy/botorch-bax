{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fd8c985",
   "metadata": {},
   "source": [
    "# Efficient pathwise posterior sample optimization - Emittance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "697d52a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import botorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from emitutils import (toy_beam_size_squared_nd, fit_gp_model_emittance, sum_samplewise_emittance_flat_X_wrapper_for_scipy, \n",
    "                       post_emit, sum_samplewise_emittance_flat_X_wrapper_for_torch)\n",
    "\n",
    "from samplingutils import draw_product_kernel_post_paths\n",
    "from utils import unif_random_sample_domain\n",
    "from utils import build_mesh_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95df5360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dylan\\SLAC\\botorch-bax\\botorch\\models\\gpytorch.py:113: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "domain = torch.tensor([[-2,2], [-35, 5]]).double()\n",
    "ndim = domain.shape[0]\n",
    "# train_x = build_mesh_domain(3, domain)[0]\n",
    "# train_x = unif_random_sample_domain(15, domain).double()\n",
    "train_x = unif_random_sample_domain(35, domain).double()\n",
    "train_y = toy_beam_size_squared_nd(train_x).double()*1e6\n",
    "\n",
    "\n",
    "\n",
    "model = fit_gp_model_emittance(train_x, train_y)\n",
    "\n",
    "\n",
    "n_samples = 5\n",
    "post_paths = draw_product_kernel_post_paths(model, n_samples=n_samples)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f72a57e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_meas = torch.linspace(*domain[-1], 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69f4ac27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1287],\n",
       "        [0.5554],\n",
       "        [0.5447],\n",
       "        [1.7603],\n",
       "        [1.5044]], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_inits = unif_random_sample_domain(n_samples, domain[:-1]).double().requires_grad_(True)\n",
    "x_inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e2cf4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(x_inits.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05e848c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-35.0000, -21.6667,  -8.3333,   5.0000])\n",
      "tensor([[30.4399,  5.7405,  5.7403, 30.4395],\n",
      "        [17.4045,  3.4577,  3.3752, 17.1571],\n",
      "        [17.2960,  3.3566,  3.3163, 17.1750],\n",
      "        [51.8338,  9.1109,  9.8733, 54.1209],\n",
      "        [43.1965,  8.0216,  8.1606, 43.6136]], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([-35.0000, -21.6667,  -8.3333,   5.0000])\n",
      "tensor([[30.4399,  5.7405,  5.7403, 30.4395],\n",
      "        [17.4045,  3.4577,  3.3752, 17.1571],\n",
      "        [17.2960,  3.3566,  3.3163, 17.1750],\n",
      "        [51.8338,  9.1109,  9.8733, 54.1209],\n",
      "        [43.1965,  8.0216,  8.1606, 43.6136]], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected size for first two dimensions of batch2 tensor to be: [5, 3] but got: [5, 5].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9076\\2077429300.py\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mtarget_func_jac_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrap_jac_for_scipy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_func_for_torch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m res = minimize(target_func_for_scipy, x_inits.flatten().detach().numpy(), bounds = domain[:-1].repeat(n_samples,1), \n\u001b[0m\u001b[0;32m     19\u001b[0m                jac = target_func_jac_callable, tol=1e-6, options = {'eps': 1e-03})\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# ################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    697\u001b[0m                                  **options)\n\u001b[0;32m    698\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m         res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[0;32m    700\u001b[0m                                callback=callback, **options)\n\u001b[0;32m    701\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[0miprint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdisp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m     sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n\u001b[0m\u001b[0;32m    307\u001b[0m                                   \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_bounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m                                   finite_diff_rel_step=finite_diff_rel_step)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\scipy\\optimize\\_optimize.py\u001b[0m in \u001b[0;36m_prepare_scalar_function\u001b[1;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;31m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;31m# calculation reduces overall function evaluations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m     sf = ScalarFunction(fun, x0, args, grad, hess,\n\u001b[0m\u001b[0;32m    264\u001b[0m                         finite_diff_rel_step, bounds, epsilon=epsilon)\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_grad_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_grad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;31m# Hessian Evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_grad\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_grad_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_grad\u001b[1;34m()\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mupdate_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mgrad\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mFD_METHODS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mgrad_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mgrad_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mngev\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mupdate_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9076\\2077429300.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mwrap_jac_for_scipy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_func_for_torch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjacobian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_func_for_torch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\torch\\autograd\\functional.py\u001b[0m in \u001b[0;36mjacobian\u001b[1;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[0mjac_i\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[assignment]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnelement\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m                 vj = _autograd_grad((out.reshape(-1)[j],), inputs,\n\u001b[0m\u001b[0;32m    671\u001b[0m                                     retain_graph=True, create_graph=create_graph)\n\u001b[0;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\torch\\autograd\\functional.py\u001b[0m in \u001b[0;36m_autograd_grad\u001b[1;34m(outputs, inputs, grad_outputs, create_graph, retain_graph, is_grads_batched)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m         return torch.autograd.grad(new_outputs, inputs, new_grad_outputs, allow_unused=True,\n\u001b[0m\u001b[0;32m    160\u001b[0m                                    \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m                                    is_grads_batched=is_grads_batched)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_vmap_internals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvjp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_none_pass_through\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_outputs_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    277\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m             allow_unused, accumulate_grad=False)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [5, 3] but got: [5, 5]."
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "target_func_for_scipy = sum_samplewise_emittance_flat_X_wrapper_for_scipy(post_paths, n_samples, X_meas)\n",
    "\n",
    "\n",
    "################################\n",
    "#with jacobian from torch (NOTE: backward doesn't work for the target function due to shape problems!)\n",
    "\n",
    "target_func_for_torch = sum_samplewise_emittance_flat_X_wrapper_for_torch(post_paths, n_samples, X_meas)\n",
    "\n",
    "def wrap_jac_for_scipy(target_func_for_torch):\n",
    "    def wrapped_func(x):\n",
    "        return torch.autograd.functional.jacobian(target_func_for_torch, torch.tensor(x)).detach().numpy()\n",
    "    return wrapped_func\n",
    "\n",
    "target_func_jac_callable = wrap_jac_for_scipy(target_func_for_torch)\n",
    "\n",
    "res = minimize(target_func_for_scipy, x_inits.flatten().detach().numpy(), bounds = domain[:-1].repeat(n_samples,1), \n",
    "               jac = target_func_jac_callable, tol=1e-6, options = {'eps': 1e-03})\n",
    "# ################################\n",
    "# #without jacobian from torch\n",
    "\n",
    "# res = minimize(target_func_for_scipy, x_inits.flatten().detach().numpy(), bounds = domain[:-1].repeat(n_samples,1), \n",
    "#                tol=1e-6, options = {'eps': 1e-03})\n",
    "\n",
    "# # ################################\n",
    "\n",
    "x_stars_flat = res.x\n",
    "\n",
    "x_stars = x_stars_flat.reshape(n_samples,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2becefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-35.0000, -21.6667,  -8.3333,   5.0000])\n",
      "tensor([[30.4399,  5.7405,  5.7403, 30.4395],\n",
      "        [17.4045,  3.4577,  3.3752, 17.1571],\n",
      "        [17.2960,  3.3566,  3.3163, 17.1750],\n",
      "        [51.8338,  9.1109,  9.8733, 54.1209],\n",
      "        [43.1965,  8.0216,  8.1606, 43.6136]], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected size for first two dimensions of batch2 tensor to be: [5, 3] but got: [5, 5].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9076\\1251599017.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtarget_func_for_torch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_inits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [5, 3] but got: [5, 5]."
     ]
    }
   ],
   "source": [
    "target_func_for_torch(x_inits.flatten()).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5ce2bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-35.0000, -21.6667,  -8.3333,   5.0000], requires_grad=True)\n",
      "tensor([[30.4399,  5.7405,  5.7403, 30.4395],\n",
      "        [17.4045,  3.4577,  3.3752, 17.1571],\n",
      "        [17.2960,  3.3566,  3.3163, 17.1750],\n",
      "        [51.8338,  9.1109,  9.8733, 54.1209],\n",
      "        [43.1965,  8.0216,  8.1606, 43.6136]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dylan\\AppData\\Local\\Temp\\ipykernel_9076\\2861227258.py:3: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "C:\\Users\\Dylan\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\torch\\autograd\\__init__.py:173: UserWarning: Error detected in LinalgLstsqBackward0. Traceback of forward call that caused the error:\n",
      "  File \"C:\\Users\\Dylan\\Anaconda3\\envs\\BOTORCH\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\Dylan\\Anaconda3\\envs\\BOTORCH\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Dylan\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Dylan\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\traitlets\\config\\application.py\", line 982, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Dylan\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Dylan\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Dylan\\Anaconda3\\envs\\BOTORCH\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Dylan\\Anaconda3\\envs\\BOTORCH\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Dylan\\Anaconda3\\envs\\BOTORCH\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Dylan\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Dylan\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Dylan\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Dylan\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Dylan\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\Dylan\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Dylan\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2974, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Dylan\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3029, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\Dylan\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Dylan\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3256, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Dylan\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3472, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\Dylan\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3552, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Dylan\\AppData\\Local\\Temp\\ipykernel_9076\\2861227258.py\", line 11, in <cell line: 3>\n",
      "    emits_sq = compute_emits_from_batched_beamsize_scans(xs_meas_test, ys_batch_test)[1]\n",
      "  File \"C:\\Users\\Dylan\\SLAC\\botorch-bax\\emitutils.py\", line 301, in compute_emits_from_batched_beamsize_scans\n",
      "    #         print(A.shape)\n",
      " (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\python_anomaly_mode.cpp:104.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (5x3 and 4x5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9076\\2861227258.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0memits_sq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_emits_from_batched_beamsize_scans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs_meas_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mys_batch_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0memits_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\BOTORCH\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (5x3 and 4x5)"
     ]
    }
   ],
   "source": [
    "from emitutils import compute_emits_from_batched_beamsize_scans\n",
    "\n",
    "with torch.autograd.detect_anomaly():\n",
    "    xs_meas_test = torch.tensor([-35.0000, -21.6667,  -8.3333,   5.0000]).requires_grad_(True)\n",
    "    ys_batch_test = torch.tensor([[30.4399,  5.7405,  5.7403, 30.4395],\n",
    "            [17.4045,  3.4577,  3.3752, 17.1571],\n",
    "            [17.2960,  3.3566,  3.3163, 17.1750],\n",
    "            [51.8338,  9.1109,  9.8733, 54.1209],\n",
    "            [43.1965,  8.0216,  8.1606, 43.6136]] ).requires_grad_(True)\n",
    "\n",
    "    emits_sq = compute_emits_from_batched_beamsize_scans(xs_meas_test, ys_batch_test)[1]\n",
    "    emits_sq.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64185b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchmin import minimize\n",
    "\n",
    "# target_func_for_torch = sum_samplewise_emittance_flat_X_wrapper_for_torch(post_paths, n_samples, X_meas)\n",
    "# res = minimize(target_func_for_torch, x_inits.flatten(), method = 'bfgs', tol=1e-6)\n",
    "\n",
    "\n",
    "# x_stars_flat = res.x\n",
    "\n",
    "# x_stars = x_stars_flat.reshape(n_samples,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61afc784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from autograd_minimize import minimize\n",
    "\n",
    "# X_tuning_init = x_inits.flatten().detach().numpy()\n",
    "\n",
    "# target_func_for_torch = sum_samplewise_emittance_flat_X_wrapper_for_torch(post_paths, n_samples, X_meas)\n",
    "# res = minimize(target_func_for_torch, X_tuning_init, backend='torch', tol=1e-6)\n",
    "\n",
    "\n",
    "# x_stars_flat = res.x\n",
    "\n",
    "# x_stars = x_stars_flat.reshape(n_samples,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b6fb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a29686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = 0\n",
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "nsteps_mesh = 100\n",
    "xs_mesh_n_by_d, x_mesh_tuple = build_mesh_domain(nsteps_mesh, domain)\n",
    "x0mesh, x1mesh = x_mesh_tuple\n",
    "ys_mesh = post_paths(xs_mesh_n_by_d).reshape(n_samples,nsteps_mesh,nsteps_mesh)\n",
    "ax.pcolor(x0mesh.detach().numpy(), x1mesh.detach().numpy(), ys_mesh[sid].detach().numpy())\n",
    "# ax.scatter(*xs_star[sid], marker='x', s=120, color='r', label='scipy min')\n",
    "\n",
    "ax.set_title('Pathwise Posterior Sample Optimization')\n",
    "ax.set_ylabel('$x_2$')\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.legend()\n",
    "\n",
    "textstr = 'sample ' + str(sid)\n",
    "\n",
    "\n",
    "# these are matplotlib.patch.Patch properties\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "\n",
    "# place a text box in upper left in axes coords\n",
    "ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=14,\n",
    "        verticalalignment='top', horizontalalignment = 'left', bbox=props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3191c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cf2fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tuning_scan = torch.linspace(*domain[0],100)\n",
    "X_tuning_scan = X_tuning_scan.reshape(-1,1)\n",
    "emits = post_emit(post_paths, X_tuning_scan, X_meas, samplewise=False, squared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a985520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_stars = post_emit(post_paths, torch.tensor(x_stars), X_meas, samplewise=True, squared=True)\n",
    "\n",
    "p = plt.plot(X_tuning_scan.flatten(), emits[0].detach().numpy(), label='post. sample')\n",
    "x_star = x_stars[0]\n",
    "emit_star = emit_stars[0]\n",
    "plt.scatter([x_star[0]],[emit_star.detach().numpy()], c=p[-1].get_color(), label='scipy min')\n",
    "\n",
    "for i in range(1, n_samples):\n",
    "    p = plt.plot(X_tuning_scan.flatten(), emits[i].detach().numpy())\n",
    "    x_star = x_stars[i]\n",
    "    emit_star = emit_stars[i]\n",
    "    plt.scatter([x_star[0]],[emit_star.detach().numpy()], c=p[-1].get_color())\n",
    "\n",
    "plt.title('Pathwise Sample $\\epsilon^2$ Optimization - 2d')\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$\\epsilon^{2}$', fontsize=14)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5d29d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms import ScipyMinimizeEmittance, GridMinimizeEmittance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6a7990",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = ScipyMinimizeEmittance(domain=domain, n_samples=5)\n",
    "# algo = GridMinimizeEmittance(domain=domain, n_samples=5, n_steps_tuning_params=10, squared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a205f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_exe, ys_exe = algo.get_exe_paths(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07c6dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_exe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b9d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_exe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d9871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e806caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652b2458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065ee6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitutils import EmittanceModule\n",
    "from botorch.generation.gen import gen_candidates_scipy\n",
    "from botorch.optim.initializers import gen_batch_initial_conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe9e7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to wrap the function for the emittance module forward pass so that it can handle a batch of flat tensor inputs\n",
    "\n",
    "emitmodule = EmittanceModule(post_paths, n_samples, X_meas)\n",
    "bounds = domain[:-1].repeat(n_samples,1).T\n",
    "Xinit = gen_batch_initial_conditions(\n",
    "        emitmodule, bounds, q=1, num_restarts=25, raw_samples=500\n",
    " )\n",
    "batch_candidates, batch_acq_values = gen_candidates_scipy(\n",
    "        initial_conditions=Xinit,\n",
    "        acquisition_function=emitmodule,\n",
    "        lower_bounds=bounds[0],\n",
    "        upper_bounds=bounds[1],\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dee7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
